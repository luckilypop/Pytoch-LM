{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbba9bf4",
   "metadata": {},
   "source": [
    "# 12.3 自动并行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9a0150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d1e3c4",
   "metadata": {},
   "source": [
    "## 12.3.1. 基于GPU的并行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c800da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = d2l.try_all_gpus()\n",
    "def run(x):\n",
    "    return [x.mm(x) for _ in range(50)]\n",
    "\n",
    "x_gpu1 = torch.rand(size=(4000, 4000), device=devices[0])\n",
    "x_gpu2 = torch.rand(size=(4000, 4000), device=devices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfdf7450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU1 time: 0.5015 sec\n",
      "GPU2 time: 0.5064 sec\n"
     ]
    }
   ],
   "source": [
    "# 通过在测量之前预热设备（对设备执行一次传递）来确保缓存的作用不影响最终的结果。\n",
    "# torch.cuda.synchronize() 函数将会等待一个 CUDA 设备上的所有流中的所有核心的计算完成。\n",
    "# 函数接受一个device 参数，代表是哪个设备需要同步。\n",
    "# 如果device参数是 None（默认值），它将使用 current_device() 找出的当前设备。\n",
    "run(x_gpu1)\n",
    "run(x_gpu2)  # 预热设备\n",
    "torch.cuda.synchronize(devices[0])\n",
    "torch.cuda.synchronize(devices[1])\n",
    "\n",
    "with d2l.Benchmark('GPU1 time'):\n",
    "    run(x_gpu1)\n",
    "    torch.cuda.synchronize(devices[0])\n",
    "\n",
    "with d2l.Benchmark('GPU2 time'):\n",
    "    run(x_gpu2)\n",
    "    torch.cuda.synchronize(devices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dba40cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU1 & GPU2: 0.5204 sec\n"
     ]
    }
   ],
   "source": [
    "# 删除两个任务之间的 synchronize 语句，系统就可以在两个设备上自动实现并行计算。\n",
    "with d2l.Benchmark('GPU1 & GPU2'):\n",
    "    run(x_gpu1)\n",
    "    run(x_gpu2)\n",
    "    torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e63f38c",
   "metadata": {},
   "source": [
    "## 12.3.2. 并行计算与通信"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a317f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在GPU1上运行: 0.5697 sec\n",
      "复制到CPU: 1.9280 sec\n"
     ]
    }
   ],
   "source": [
    "def copy_to_cpu(x, non_blocking=False):\n",
    "    return [y.to('cpu', non_blocking=non_blocking) for y in x]\n",
    "\n",
    "with d2l.Benchmark('在GPU1上运行'):\n",
    "    y = run(x_gpu1)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "with d2l.Benchmark('复制到CPU'):\n",
    "    y_cpu = copy_to_cpu(y)\n",
    "    torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c54b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在GPU1上运行并复制到CPU: 1.4775 sec\n"
     ]
    }
   ],
   "source": [
    "with d2l.Benchmark('在GPU1上运行并复制到CPU'):\n",
    "    y = run(x_gpu1)\n",
    "    y_cpu = copy_to_cpu(y, True)\n",
    "    torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a57446",
   "metadata": {},
   "source": [
    "## 12.3.3 小结\n",
    "\n",
    "* 现代系统拥有多种设备，如多个 GPU 和多个 CPU，还可以并行地、异步地使用它们。\n",
    "* 现代系统还拥有各种通信资源，如PCI Express、存储（通常是固态硬盘或网络存储）和网络带宽，为了达到最高效率可以并行使用它们。\n",
    "* 后端可以通过自动化地并行计算和通信来提高性能。"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:d2l] *",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
