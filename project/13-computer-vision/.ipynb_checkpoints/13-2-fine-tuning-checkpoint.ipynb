{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db53965",
   "metadata": {},
   "source": [
    "# 13.2. 微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b10de",
   "metadata": {},
   "source": [
    "## 13.2.1. 步骤\n",
    "在本节中，我们将介绍迁移学习中的常见技巧 : *微调*（fine-tuning）。如 :numref:`fig_finetune` 所示，微调包括以下四个步骤： \n",
    "\n",
    "1. 在源数据集（例如 ImageNet 数据集）上预训练神经网络模型，即 *源模型*。\n",
    "1. 创建一个新的神经网络模型，即 *目标模型*。这将复制源模型上的所有模型设计及其参数，但输出层除外。我们假定这些模型参数包含从源数据集中学到的知识，这些知识也将适用于目标数据集。我们还假设源模型的输出层与源数据集的标签密切相关；因此不在目标模型中使用该层。\n",
    "1. 向目标模型添加输出层，其输出数量是目标数据集中的类别数。然后随机初始化该层的模型参数。\n",
    "1. 在目标数据集（如椅子数据集）上训练目标模型。输出层将从头开始进行训练，而所有其他层的参数将根据源模型的参数进行微调。\n",
    "\n",
    "![微调。](https://zh-v2.d2l.ai/_images/finetune.svg)\n",
    ":label:`fig_finetune`\n",
    "\n",
    "当目标数据集比源数据集小得多时，微调有助于提高模型的泛化能力。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd685f0",
   "metadata": {},
   "source": [
    "## 13.2.2. 热狗识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9465432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22646747",
   "metadata": {},
   "source": [
    "### 获取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ac0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data/hotdog.zip from http://d2l-data.s3-accelerate.amazonaws.com/hotdog.zip...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 解压下载的数据集后，我们获得了两个文件夹 hotdog/train 和 hotdog/test。\n",
    "# 这两个文件夹都有 hotdog 和 not-hotdog 个子文件夹，\n",
    "# 其中任何一个文件夹都包含相应类的图像。\n",
    "#@save\n",
    "d2l.DATA_HUB['hotdog'] = (d2l.DATA_URL + 'hotdog.zip',\n",
    "                         'fba480ffa8aa7e0febbb511d181409f899b9baa5')\n",
    "\n",
    "data_dir = d2l.download_extract('hotdog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccfe97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建两个实例来分别读取训练和测试数据集中的所有图像文件。\n",
    "train_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'))\n",
    "test_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682fad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面显示了前 8 个正面示例和最后 8 张负面图片。\n",
    "hotdogs = [train_imgs[i][0] for i in range(8)]\n",
    "not_hotdogs = [train_imgs[-i - 1][0] for i in range(8)]\n",
    "d2l.show_images(hotdogs + not_hotdogs, 2, 8, scale=1.4);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b60baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练期间，我们首先从图像中裁切随机大小和随机长宽比的区域，\n",
    "# 然后将该区域缩放为 224×224 输入图像。 \n",
    "# 在测试过程中，我们将图像的高度和宽度都缩放到 256 像素，然后裁剪中央 224×224 区域作为输入。 \n",
    "# 此外，对于三个 RGB（红、绿和蓝）颜色通道，我们 标准化每个通道。 \n",
    "#具体而言，通道的平均值将从该通道的每个值中减去，然后将结果除以该通道的标准差。\n",
    "\n",
    "# 使用三个RGB通道的均值和标准偏差，以标准化每个通道\n",
    "normalize = torchvision.transforms.Normalize(\n",
    "    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "test_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903630f1",
   "metadata": {},
   "source": [
    "### 定义和初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cabfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 使用在 ImageNet 数据集上预训练的 Resnet-18 作为源模型。\n",
    "# 在这里，我们指定 pretrained=True 以自动下载预训练的模型参数。\n",
    "pretrained_net = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面给出了源模型的变量 fc。\n",
    "pretrained_net.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacabe2a",
   "metadata": {},
   "source": [
    "- 在 ResNet 的全局平均池化后，全连接层汇集转换为 ImageNet 数据集的 1000 个类输出。\n",
    "- 之后，我们构建一个新的神经网络作为目标模型。 \n",
    "- 它的定义方式与预训练源模型的定义方式相同，只是最终层中的输出数量被设置为目标数据集中的类数（而不是1000个）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8219ef",
   "metadata": {},
   "source": [
    "- 初始化目标模型实例 finetune_net 输出层之前的模型参数，以对源模型中相应层的参数进行建模。\n",
    "- 由于这些模型参数是通过 ImageNet 上的预训练获得的，因此它们很有效，\n",
    "- 所以我们只需使用较小的学习率进行 微调 这样的预训练参数。\n",
    "- 输出层中的模型参数是随机初始化的，通常需要更高的学习率，从头开始学习。 \n",
    "- 这里，我们设基本学习率为 η，迭代输出层学习率为 10η。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50896ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_net = torchvision.models.resnet18(pretrained=True)\n",
    "finetune_net.fc = nn.Linear(finetune_net.fc.in_features, 2)\n",
    "nn.init.xavier_uniform_(finetune_net.fc.weight);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899572e",
   "metadata": {},
   "source": [
    "### 微调模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c7a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义了一个训练函数 train_fine_tuning，该函数使用微调，因此可以多次调用。\n",
    "# 如果 `param_group=True`，输出层中的模型参数将使用十倍的学习率\n",
    "def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5,\n",
    "                      param_group=True):\n",
    "    train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'train'), transform=train_augs),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'test'), transform=test_augs),\n",
    "        batch_size=batch_size)\n",
    "    devices = d2l.try_all_gpus()\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    if param_group:\n",
    "        params_1x = [param for name, param in net.named_parameters()\n",
    "             if name not in [\"fc.weight\", \"fc.bias\"]]\n",
    "        trainer = torch.optim.SGD([{'params': params_1x},\n",
    "                                   {'params': net.fc.parameters(),\n",
    "                                    'lr': learning_rate * 10}],\n",
    "                                lr=learning_rate, weight_decay=0.001)\n",
    "    else:\n",
    "        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate,\n",
    "                                  weight_decay=0.001)\n",
    "    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,\n",
    "                   devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ff844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用较小的学习率，通过微调预训练获得的模型参数。\n",
    "train_fine_tuning(finetune_net, 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38401351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了进行比较，我们定义了一个相同的模型，但是将其所有模型参数初始化为随机值。 \n",
    "# 由于整个模型需要从头开始训练，因此我们需要使用更大的学习率。\n",
    "scratch_net = torchvision.models.resnet18()\n",
    "scratch_net.fc = nn.Linear(scratch_net.fc.in_features, 2)\n",
    "train_fine_tuning(scratch_net, 5e-4, param_group=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc63e3c",
   "metadata": {},
   "source": [
    "## 13.2.3 小结\n",
    "\n",
    "* 迁移学习将从源数据集中学到的知识“迁移”到目标数据集，微调是迁移学习的常见技巧。\n",
    "* 除输出层外，目标模型从源模型中复制所有模型设计及其参数，并根据目标数据集对这些参数进行微调。但是，目标模型的输出层需要从头开始训练。\n",
    "* 通常，微调参数使用较小的学习率，而从头开始训练输出层可以使用更大的学习率。"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:d2l] *",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
